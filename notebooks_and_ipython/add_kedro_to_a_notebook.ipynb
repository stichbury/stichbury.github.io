{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2dbc66a",
   "metadata": {},
   "source": [
    "# Add Kedro features to a notebook\n",
    "\n",
    "This page describes how to add Kedro features incrementally to a notebook. \n",
    "\n",
    "It starts with a version of the spaceflights example with does NOT use Kedro that you can run inside a notebook. The example converts portions of the code to use Kedro features while remaining runnable from within a notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85737b7",
   "metadata": {},
   "source": [
    "## Spaceflights in a notebook\n",
    "\n",
    "If you are unfamiliar with the spaceflights example, it is used to introduce the basics of Kedro in a tutorial that runs exclusively as a Kedro project, that is, as a set of `.py` files rather than in a notebook. The premise is as follows:\n",
    "\n",
    "_It is 2160, and the space tourism industry is booming. Globally, thousands of space shuttle companies take tourists to the Moon and back. You have been able to source data that lists the amenities offered in each space shuttle, customer reviews, and company information._\n",
    "\n",
    "_Project: You want to construct a model that predicts the price for each trip to the Moon and the corresponding return flight._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f406dc0",
   "metadata": {},
   "source": [
    "### The notebook example\n",
    "The full example code is given below. In a real notebook example, it would most likely be split across multiple cells with various additional code added to inspect and explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca8e81-e49c-4c75-b80b-e27b2c61682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This code needs the data folder set up and three files downloaded. \n",
    "# Is there a way to do this in code from the notebook to save the reader the manual task?\n",
    "# Either download the file or use an OS data fabricator to make 3 files?\n",
    "\n",
    "companies = pd.read_csv('data/companies.csv')\n",
    "reviews = pd.read_csv('data/reviews.csv')\n",
    "shuttles = pd.read_excel('data/shuttles.xlsx', engine='openpyxl')\n",
    "\n",
    "# Data processing\n",
    "companies[\"iata_approved\"] = companies[\"iata_approved\"] == \"t\"\n",
    "companies[\"company_rating\"] = companies[\"company_rating\"].str.replace(\"%\", \"\").astype(float)\n",
    "shuttles[\"d_check_complete\"] = shuttles[\"d_check_complete\"] == \"t\"\n",
    "shuttles[\"moon_clearance_complete\"] = shuttles[\"moon_clearance_complete\"] == \"t\"\n",
    "shuttles[\"price\"] = shuttles[\"price\"].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "rated_shuttles = shuttles.merge(reviews, left_on=\"id\", right_on=\"shuttle_id\")\n",
    "model_input_table = rated_shuttles.merge(companies, left_on=\"company_id\", right_on=\"id\")\n",
    "model_input_table = model_input_table.dropna()\n",
    "model_input_table.head()\n",
    "\n",
    "# Model evaluation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = model_input_table[[\n",
    "    \"engines\",\n",
    "    \"passenger_capacity\",\n",
    "    \"crew\",\n",
    "    \"d_check_complete\",\n",
    "    \"moon_clearance_complete\",\n",
    "    \"iata_approved\",\n",
    "    \"company_rating\",\n",
    "    \"review_scores_rating\",\n",
    "]]\n",
    "y = model_input_table[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = model.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a5b8dc",
   "metadata": {},
   "source": [
    "## Use Kedro for data processing\n",
    "Even if you’re not ready for a full Kedro project, you can still take advantage of its data handling solution in your existing project from within a notebook. This section shows you how.\n",
    "\n",
    "Kedro’s Data Catalog is a registry of all data sources available for use by the project, and offers a separate place to declare details of the datasets your projects use. Kedro provides [built-in datasets for numerous file types and file systems](https://docs.kedro.org/en/stable/kedro_datasets.html), so you don’t have to write any of the logic for reading or writing data. \n",
    "\n",
    "Kedro offers a range of datasets, including CSV, Excel, Parquet, Feather, HDF5, JSON, Pickle, SQL Tables, SQL Queries, Spark DataFrames and more. They are supported with the APIs of pandas, spark, networkx, matplotlib, yaml and more. It relies on `[fsspec](https://filesystem-spec.readthedocs.io/en/latest/)` to read and save data from a variety of data stores including local file systems, network file systems, cloud object stores, and Hadoop. You can pass arguments in to load and save operations, and use versioning and credentials for data access.\n",
    "\n",
    "To start using the Data Catalog, create a `catalog.yml` in the same folder as your notebook to define datasets that can be used when writing your functions. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a60b69",
   "metadata": {},
   "source": [
    "<!--This code needs the user to create a yaml file with this contents. Is there a piece of code we could offer that creates and writes one for them into the appropriate directory to save the reader the manual task? -->\n",
    "\n",
    "```yml\n",
    "companies:\n",
    "  type: pandas.CSVDataSet\n",
    "  filepath: data/companies.csv\n",
    "\n",
    "reviews:\n",
    "  type: pandas.CSVDataSet\n",
    "  filepath: data/reviews.csv\n",
    "\n",
    "shuttles:\n",
    "  type: pandas.ExcelDataSet\n",
    "  filepath: data/shuttles.xlsx\n",
    "```\n",
    "\n",
    "Then by using Kedro to load the `catalog.yml` file, you can reference the Data Catalog in your notebook as you load the data for data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kedro's DataCatalog\n",
    "\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "import yaml\n",
    "# load the configuration file \n",
    "with open(\"catalog.yml\") as f:\n",
    "    conf_catalog = yaml.safe_load(f)\n",
    "\n",
    "# Create the DataCatalog instance from the configuration\n",
    "catalog = DataCatalog.from_config(conf_catalog)\n",
    "\n",
    "# Load the datasets\n",
    "companies = catalog.load(\"companies\")\n",
    "reviews = catalog.load(\"reviews\")\n",
    "shuttles = catalog.load(\"shuttles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece5ef08",
   "metadata": {},
   "source": [
    "The rest of the spaceflights notebook code for data processing and model evaluation from above can now run as previously. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be50bb",
   "metadata": {},
   "source": [
    "## Use a YAML configuration file\n",
    "\n",
    "### Use a configuration file just for \"magic numbers\"\n",
    "When writing exploratory code, it’s tempting to hard code values to save time, but it makes code harder to maintain in the longer-term. The example code for model evaluation above calls `sklearn.model_selection.train_test_split()`, passing in a model input table and outputs the test and train datasets. There are hard-code values supplied to `test_size` and `random_state`.\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "```\n",
    "\n",
    "[Good software engineering practice](https://towardsdatascience.com/five-software-engineering-principles-for-collaborative-data-science-ab26667a311) suggests that we extract *‘magic numbers’* into named constants, sometimes defined at the top of a file, or outside in a utility file, storing it in a format such as yaml. \n",
    "\n",
    "<!--This code needs the user to create a yaml file with this contents. Is there a piece of code we could offer that creates and writes one for them into the appropriate directory to save the reader the manual task? -->\n",
    "\n",
    "```yml\n",
    "# params.yml\n",
    "\n",
    "model_options:\n",
    "  test_size: 0.3\n",
    "  random_state: 3\n",
    "```  \n",
    "\n",
    "By loading `params.yml`, you can reference the values with the notebook code. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"params.yml\", encoding=\"utf-8\") as yaml_file:\n",
    "    params=yaml.safe_load(yaml_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0fb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = params[\"model_options\"][\"test_size\"]\n",
    "random_state = params[\"model_options\"][\"random_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"engines\",\n",
    "    \"passenger_capacity\",\n",
    "    \"crew\",\n",
    "    \"d_check_complete\",\n",
    "    \"moon_clearance_complete\",\n",
    "    \"iata_approved\",\n",
    "    \"company_rating\",\n",
    "    \"review_scores_rating\",\n",
    "]\n",
    "                                                                                                                                                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b47601",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_input_table[features]\n",
    "y = model_input_table[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7639d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ad5afa",
   "metadata": {},
   "source": [
    "The rest of the model evaluation code can now run as previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = model.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbe807d",
   "metadata": {},
   "source": [
    "### Use a configuration file for all \"magic values\"\n",
    "If we extend the concept of magic numbers to encompass magic values in general, we might also see that the variable features also seems like it might be reusable elsewhere. Extracting it from code into `parameters.yml` leads to the following:\n",
    "\n",
    "<!--This code needs the user to create a yaml file with this contents. Is there a piece of code we could offer that creates and writes one for them into the appropriate directory to save the reader the manual task? -->\n",
    "\n",
    "```yml\n",
    "# parameters.yml \n",
    "\n",
    "model_options:\n",
    "  test_size: 0.3\n",
    "  random_state: 3\n",
    "  features:\n",
    "    - engines\n",
    "    - passenger_capacity\n",
    "    - crew\n",
    "    - d_check_complete\n",
    "    - moon_clearance_complete\n",
    "    - iata_approved\n",
    "    - company_rating\n",
    "    - review_scores_rating\n",
    "```\n",
    "\n",
    "The code now looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2788152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "\n",
    "with open(\"parameters.yaml\", encoding=\"utf-8\") as yaml_file:\n",
    "    parameters = yaml.safe_load(yaml_file)\n",
    "\n",
    "test_size = parameters[\"model_options\"][\"test_size\"]\n",
    "random_state = parameters[\"model_options\"][\"random_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8046b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_input_table[parameters[\"model_options\"][\"features\"]]\n",
    "y = model_input_table[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251fbaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb05656b",
   "metadata": {},
   "source": [
    "The rest of the model evaluation code can now run as previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e3d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = model.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e707abf",
   "metadata": {},
   "source": [
    "## Use Kedro configuration\n",
    "Kedro offers a [configuration loader](https://docs.kedro.org/en/stable/kedro.config.ConfigLoader.html) to abstract loading values from a yaml file. You can use Kedro configuration loading without a full Kedro project and this approach replaces the need to load the configuration file with `yaml.safe_load`.\n",
    "\n",
    "### Use Kedro's configuration loader to load \"magic values\"\n",
    "There is some setup to get this working initially:\n",
    "\n",
    "1. In your notebook folder, create a subfolder called `conf`. \n",
    "2. Within the `conf` subfolder, create a subfolder called `base`. \n",
    "3. Copy `parameters.yml` into `conf/base/` so you have a file with the path `conf/base/parameters.yml`.\n",
    "4. Within the `conf` subfolder, create another subfolder called `local`. \n",
    "\n",
    "After this setup, you can use Kedro's `OmegaConfigLoader` in code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.framework.project import settings\n",
    "\n",
    "conf_loader = OmegaConfigLoader(\"conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_params=conf_loader[\"parameters\"]\n",
    "test_size = conf_params[\"model_options\"][\"test_size\"]\n",
    "random_state = conf_params[\"model_options\"][\"random_state\"]\n",
    "X = model_input_table[conf_params[\"model_options\"][\"features\"]]\n",
    "y = model_input_table[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25543f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb4497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "The rest of the model evaluation code can now run as previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = model.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d0b38",
   "metadata": {},
   "source": [
    "### Use Kedro's configuration loader to load the Data Catalog\n",
    "We have seen how to use Kedro's Data Catalog to load a `yaml` file, with `safe_load` and pass it to the `DataCatalog` class. \n",
    "\n",
    "```python\n",
    "# Using Kedro's DataCatalog\n",
    "\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "import yaml\n",
    "# load the configuration file \n",
    "with open(\"catalog.yml\") as f:\n",
    "    conf_catalog = yaml.safe_load(f)\n",
    "\n",
    "# Create the DataCatalog instance from the configuration\n",
    "catalog = DataCatalog.from_config(conf_catalog)\n",
    "\n",
    "# Load the datasets\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accda175",
   "metadata": {},
   "source": [
    "It's also possible to use the configuration loader to initialise the Data Catalog. As we saw from loading parameter values, there is some initial setup because of the Kedro project structure:\n",
    "\n",
    "1. If you haven't already, in your notebook folder, create a subfolder called `conf`. \n",
    "2. Within the `conf` subfolder, create a subfolder called `base`. \n",
    "3. Copy your `catalog.yml` into `conf/base/` so you have a file with the path `conf/base/catalog.yml`.\n",
    "4. Within the `conf` subfolder, if you haven't already, create a subfolder called `local`. \n",
    "\n",
    "After this setup, you can use Kedro's `OmegaConfigLoader` in code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1bb6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are using Kedro's ConfigLoader alongside the DataCatalog\n",
    "\n",
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.framework.project import settings\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "conf_loader = OmegaConfigLoader(\"conf\")\n",
    "conf_catalog=conf_loader[\"catalog\"]\n",
    "\n",
    "# Create the DataCatalog instance from the configuration\n",
    "catalog = DataCatalog.from_config(conf_catalog)\n",
    "\n",
    "# Load the datasets\n",
    "companies = catalog.load(\"companies\")\n",
    "reviews = catalog.load(\"reviews\")\n",
    "shuttles = catalog.load(\"shuttles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79e3ae",
   "metadata": {},
   "source": [
    "## Where next?\n",
    "At this point in the notebook, we've introduced Kedro data management (using the Data Catalog) and configuration loader. TO DO -- ADD SOME REASONING FOR WHY KEDRO ENCOURAGES THIS AND LINK TO BEST PRACTICES. You have now \"Kedro-ised\" the notebook code to make it more reusable in future. However, you can go further if your ultimate goal is to migrate code out of the notebook and use it in a full-blown Kedro project. \n",
    "\n",
    "## Refactor your code into functions\n",
    "Code in a Kedro project runs in one or more pipelines, where a pipeline is a series of nodes, which wrap discrete functions. If your ultimate goal is to create a Kedro project and use it to run your notebook code, you'll need to take the code that processes the data, and the code that calls the data science model, and make it into one or more nodes. \n",
    "\n",
    "One option is to simply put everything into a single function. Let's try this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Kedro for data management and configuration\n",
    "\n",
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.framework.project import settings\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "conf_loader = OmegaConfigLoader(\"conf\")\n",
    "conf_catalog=conf_loader[\"catalog\"]\n",
    "conf_params=conf_loader[\"parameters\"]\n",
    "\n",
    "# Create the DataCatalog instance from the configuration\n",
    "catalog = DataCatalog.from_config(conf_catalog)\n",
    "\n",
    "# Load the datasets\n",
    "companies = catalog.load(\"companies\")\n",
    "reviews = catalog.load(\"reviews\")\n",
    "shuttles = catalog.load(\"shuttles\")\n",
    "\n",
    "# Load the configuration data\n",
    "test_size = conf_params[\"model_options\"][\"test_size\"]\n",
    "random_state = conf_params[\"model_options\"][\"random_state\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caec940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_function():\n",
    "    \n",
    "    ####################\n",
    "    # Data processing  #\n",
    "    ####################\n",
    "    companies[\"iata_approved\"] = companies[\"iata_approved\"] == \"t\"\n",
    "    companies[\"company_rating\"] = companies[\"company_rating\"].str.replace(\"%\", \"\").astype(float)\n",
    "    shuttles[\"d_check_complete\"] = shuttles[\"d_check_complete\"] == \"t\"\n",
    "    shuttles[\"moon_clearance_complete\"] = shuttles[\"moon_clearance_complete\"] == \"t\"\n",
    "    shuttles[\"price\"] = shuttles[\"price\"].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "    rated_shuttles = shuttles.merge(reviews, left_on=\"id\", right_on=\"shuttle_id\")\n",
    "    model_input_table = rated_shuttles.merge(companies, left_on=\"company_id\", right_on=\"id\")\n",
    "    model_input_table = model_input_table.dropna()\n",
    "    model_input_table.head()\n",
    "\n",
    "    X = model_input_table[conf_params[\"model_options\"][\"features\"]]\n",
    "    y = model_input_table[\"price\"]\n",
    "\n",
    "    ####################\n",
    "    # Model evaluation  #\n",
    "    ####################  \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state)\n",
    " \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    model.predict(X_test)\n",
    "    from sklearn.metrics import r2_score\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc4974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the one big function\n",
    "big_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9753d0e",
   "metadata": {},
   "source": [
    "In truth, this code is not much more maintainable than if it were spread throughout multiple notebook cells. Maybe we could do better with a series of smaller functions, which would map more clearly to the Kedro vision of a pipeline that comprises a series of nodes, each of which behave consistently, repeatably and predictably, so that a given input  to a node always returns the same output. For those in the know, this is the definition of a pure function (LINK) and, as per software engineering best practice for readable code (LINK AGAIN), nodes/pure functions should be small single responsibility functions that perform a single specific task.  \n",
    "\n",
    "Let's try this with our code. We'll split it into a set of functions to process the data, which are based on the code in `big_function` but where each function has a single responsibility. Then we'll add a set of model evaluation functions which similarly use the code we've written previously but split into three separate functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47bf764",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Data processing  #\n",
    "####################\n",
    "import pandas as pd\n",
    "\n",
    "def _is_true(x: pd.Series) -> pd.Series:\n",
    "    return x == \"t\"\n",
    "\n",
    "\n",
    "def _parse_percentage(x: pd.Series) -> pd.Series:\n",
    "    x = x.str.replace(\"%\", \"\")\n",
    "    x = x.astype(float) / 100\n",
    "    return x\n",
    "\n",
    "\n",
    "def _parse_money(x: pd.Series) -> pd.Series:\n",
    "    x = x.str.replace(\"$\", \"\").str.replace(\",\", \"\")\n",
    "    x = x.astype(float)\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess_companies(companies: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    companies[\"iata_approved\"] = _is_true(companies[\"iata_approved\"])\n",
    "    companies[\"company_rating\"] = _parse_percentage(companies[\"company_rating\"])\n",
    "    return companies\n",
    "\n",
    "\n",
    "def preprocess_shuttles(shuttles: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    shuttles[\"d_check_complete\"] = _is_true(shuttles[\"d_check_complete\"])\n",
    "    shuttles[\"moon_clearance_complete\"] = _is_true(shuttles[\"moon_clearance_complete\"])\n",
    "    shuttles[\"price\"] = _parse_money(shuttles[\"price\"])\n",
    "    return shuttles\n",
    "\n",
    "def create_model_input_table(\n",
    "    shuttles: pd.DataFrame, companies: pd.DataFrame, reviews: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    rated_shuttles = shuttles.merge(reviews, left_on=\"id\", right_on=\"shuttle_id\")\n",
    "    model_input_table = rated_shuttles.merge(\n",
    "        companies, left_on=\"company_id\", right_on=\"id\"\n",
    "    )\n",
    "    model_input_table = model_input_table.dropna()\n",
    "    return model_input_table\n",
    "\n",
    "\n",
    "####################\n",
    "# Model evaluation #\n",
    "####################\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data: pd.DataFrame, parameters: Dict) -> Tuple:\n",
    "    X = data[parameters[\"features\"]]\n",
    "    y = data[\"price\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=parameters[\"test_size\"], random_state=parameters[\"random_state\"]\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def train_model(X_train: pd.DataFrame, y_train: pd.Series) -> LinearRegression:\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    return regressor\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    regressor: LinearRegression, X_test: pd.DataFrame, y_test: pd.Series\n",
    "):\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    print(r2_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388aaa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call data processing functions\n",
    "preprocessed_companies = preprocess_companies(companies)\n",
    "preprocessed_shuttles = preprocess_shuttles(shuttles)\n",
    "model_input_table = create_model_input_table(preprocessed_shuttles, preprocessed_companies, reviews)\n",
    "\n",
    "# Call model evaluation functions\n",
    "X_train, X_test, y_train, y_test = split_data(model_input_table, conf_params[\"model_options\"])\n",
    "regressor = train_model(X_train, y_train)\n",
    "evaluate_model(regressor, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a37ff",
   "metadata": {},
   "source": [
    "And that's it. The notebook code has been refactored into a series of functions that use some Kedro setup code to read in configuration values and data. Let's reproduce it all in one big notebook cell for reference so you can see how it looks in comparison to the first cell of the notebook that was the start of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7fe82d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/04/23 14:53:42] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'companies'</span> <span style=\"font-weight: bold\">(</span>CSVDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                      <a href=\"file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py#501\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/04/23 14:53:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'companies'\u001b[0m \u001b[1m(\u001b[0mCSVDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                      \u001b]8;id=865121;file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=743313;file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py#501\u001b\\\u001b[2m501\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'reviews'</span> <span style=\"font-weight: bold\">(</span>CSVDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                        <a href=\"file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py#501\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'reviews'\u001b[0m \u001b[1m(\u001b[0mCSVDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                        \u001b]8;id=244746;file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=833585;file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py#501\u001b\\\u001b[2m501\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'shuttles'</span> <span style=\"font-weight: bold\">(</span>ExcelDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <a href=\"file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py#501\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'shuttles'\u001b[0m \u001b[1m(\u001b[0mExcelDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                     \u001b]8;id=676014;file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=770141;file:///Users/jo_stichbury/Documents/GitHub/kedro/kedro/io/data_catalog.py#501\u001b\\\u001b[2m501\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/04/23 14:53:52] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"color: #800080; text-decoration-color: #800080\">/var/folders/1k/dv_x85xj37ldpdp2ff099lrh0000gn/T/ipykernel_45577/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">99869</span> <a href=\"file:///Users/jo_stichbury/opt/anaconda3/envs/py38/lib/python3.8/warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/jo_stichbury/opt/anaconda3/envs/py38/lib/python3.8/warnings.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">9662.py</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span>: FutureWarning: The default value of regex will change from <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> to <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> in a future version. In addition, single character       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         regular expressions will *not* be treated as literal strings when      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #808000; text-decoration-color: #808000\">regex</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>.                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           x = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">x.str.replace</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"$\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span><span style=\"font-weight: bold\">)</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.str.replace</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\",\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span><span style=\"font-weight: bold\">)</span>                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/04/23 14:53:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/var/folders/1k/dv_x85xj37ldpdp2ff099lrh0000gn/T/ipykernel_45577/\u001b[0m\u001b[95m99869\u001b[0m \u001b]8;id=175246;file:///Users/jo_stichbury/opt/anaconda3/envs/py38/lib/python3.8/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=798706;file:///Users/jo_stichbury/opt/anaconda3/envs/py38/lib/python3.8/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[95m9662.py\u001b[0m:\u001b[1;36m39\u001b[0m: FutureWarning: The default value of regex will change from \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[3;92mTrue\u001b[0m to \u001b[3;91mFalse\u001b[0m in a future version. In addition, single character       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         regular expressions will *not* be treated as literal strings when      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[33mregex\u001b[0m=\u001b[3;92mTrue\u001b[0m.                                                            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           x = \u001b[1;35mx.str.replace\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"$\"\u001b[0m, \u001b[32m\"\"\u001b[0m\u001b[1m)\u001b[0m\u001b[1;35m.str.replace\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\",\"\u001b[0m, \u001b[32m\"\"\u001b[0m\u001b[1m)\u001b[0m                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45853658630609717\n"
     ]
    }
   ],
   "source": [
    "# Kedro setup for data management and configuration\n",
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.framework.project import settings\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "conf_loader = OmegaConfigLoader(\"conf\")\n",
    "conf_catalog=conf_loader[\"catalog\"]\n",
    "conf_params=conf_loader[\"parameters\"]\n",
    "\n",
    "# Create the DataCatalog instance from the configuration\n",
    "catalog = DataCatalog.from_config(conf_catalog)\n",
    "\n",
    "# Load the datasets\n",
    "companies = catalog.load(\"companies\")\n",
    "reviews = catalog.load(\"reviews\")\n",
    "shuttles = catalog.load(\"shuttles\")\n",
    "\n",
    "# Load the configuration data\n",
    "test_size = conf_params[\"model_options\"][\"test_size\"]\n",
    "random_state = conf_params[\"model_options\"][\"random_state\"]\n",
    "\n",
    "\n",
    "####################\n",
    "# Data processing  #\n",
    "####################\n",
    "import pandas as pd\n",
    "\n",
    "def _is_true(x: pd.Series) -> pd.Series:\n",
    "    return x == \"t\"\n",
    "\n",
    "\n",
    "def _parse_percentage(x: pd.Series) -> pd.Series:\n",
    "    x = x.str.replace(\"%\", \"\")\n",
    "    x = x.astype(float) / 100\n",
    "    return x\n",
    "\n",
    "\n",
    "def _parse_money(x: pd.Series) -> pd.Series:\n",
    "    x = x.str.replace(\"$\", \"\").str.replace(\",\", \"\")\n",
    "    x = x.astype(float)\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess_companies(companies: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    companies[\"iata_approved\"] = _is_true(companies[\"iata_approved\"])\n",
    "    companies[\"company_rating\"] = _parse_percentage(companies[\"company_rating\"])\n",
    "    return companies\n",
    "\n",
    "\n",
    "def preprocess_shuttles(shuttles: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    shuttles[\"d_check_complete\"] = _is_true(shuttles[\"d_check_complete\"])\n",
    "    shuttles[\"moon_clearance_complete\"] = _is_true(shuttles[\"moon_clearance_complete\"])\n",
    "    shuttles[\"price\"] = _parse_money(shuttles[\"price\"])\n",
    "    return shuttles\n",
    "\n",
    "def create_model_input_table(\n",
    "    shuttles: pd.DataFrame, companies: pd.DataFrame, reviews: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    rated_shuttles = shuttles.merge(reviews, left_on=\"id\", right_on=\"shuttle_id\")\n",
    "    model_input_table = rated_shuttles.merge(\n",
    "        companies, left_on=\"company_id\", right_on=\"id\"\n",
    "    )\n",
    "    model_input_table = model_input_table.dropna()\n",
    "    return model_input_table\n",
    "\n",
    "\n",
    "####################\n",
    "# Model evaluation #\n",
    "####################\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data: pd.DataFrame, parameters: Dict) -> Tuple:\n",
    "    X = data[parameters[\"features\"]]\n",
    "    y = data[\"price\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=parameters[\"test_size\"], random_state=parameters[\"random_state\"]\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def train_model(X_train: pd.DataFrame, y_train: pd.Series) -> LinearRegression:\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    return regressor\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    regressor: LinearRegression, X_test: pd.DataFrame, y_test: pd.Series\n",
    "):\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    print(r2_score(y_test, y_pred))\n",
    "\n",
    "    \n",
    "# Call data processing functions\n",
    "preprocessed_companies = preprocess_companies(companies)\n",
    "preprocessed_shuttles = preprocess_shuttles(shuttles)\n",
    "model_input_table = create_model_input_table(preprocessed_shuttles, preprocessed_companies, reviews)\n",
    "\n",
    "# Call model evaluation functions\n",
    "X_train, X_test, y_train, y_test = split_data(model_input_table, conf_params[\"model_options\"])\n",
    "regressor = train_model(X_train, y_train)\n",
    "evaluate_model(regressor, X_test, y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f015570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
